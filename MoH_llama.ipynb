{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cdf6aa-8caa-4136-acec-8ae1731885ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers accelerate bitsandbytes datasets matplotlib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d18b81e-d791-4dbb-b660-49419b709752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81d7ffe5-3554-4ccf-97e0-047a7387ddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "from transformers.models.llama.modeling_llama import LlamaAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0bf44e3-8b50-43fc-986a-9ff57056bad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"TinyLlama/TinyLlama_v1.1\"\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map={\"\": device},\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "print(\"Model loaded on:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b2b681-882c-428a-b55f-d5f70dba77e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9120c19e-b89c-4573-80b8-413b32f33e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7541bbdebdb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fix seed\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fea5e87e-d2b6-4472-a6fc-b34a3646de64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MMLU and GSM8K subsets...\n",
      "MMLU subset size: 451\n",
      "GSM8K subset size: 131\n",
      "Perplexity texts mmlu: 451\n",
      "Perplexity texts gsm8k: 131\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading MMLU and GSM8K subsets...\")\n",
    "\n",
    "mmlu = load_dataset(\"cais/mmlu\", \"all\", split=\"test\")\n",
    "# We'll use the \"test\" split from a subset of subjects\n",
    "mmlu_subjects = [\n",
    "    \"abstract_algebra\",\n",
    "    \"high_school_physics\",\n",
    "    \"college_chemistry\",\n",
    "    \"high_school_computer_science\"\n",
    "]\n",
    "\n",
    "mmlu_examples = []\n",
    "#print(mmlu)\n",
    "for subj in mmlu_subjects:\n",
    "    ds = load_dataset(\"cais/mmlu\", subj, split=\"test\")\n",
    "    #print(ds)\n",
    "\n",
    "    num_ex = max(100, len(ds[\"question\"]))\n",
    "    for idx in range(num_ex):\n",
    "        # Normalize choices/options\n",
    "        choices = ds[\"choices\"][idx] \n",
    "        answer_idx = ds[\"answer\"][idx]  \n",
    "\n",
    "        # Only keep four-choice questions\n",
    "        if len(choices) != 4:\n",
    "            continue\n",
    "    \n",
    "        mmlu_examples.append({\n",
    "            \"question\": ds[\"question\"][idx],\n",
    "            \"choices\": choices,\n",
    "            \"answer_idx\": int(answer_idx),\n",
    "        })\n",
    "\n",
    "print(\"MMLU subset size:\", len(mmlu_examples))\n",
    "gsm8k = load_dataset(\"openai/gsm8k\", \"main\", split=\"test\")\n",
    "k = max(1, min(int(0.1 * len(gsm8k)), 300))\n",
    "idxs = random.sample(range(len(gsm8k)), k)\n",
    "gsm8k_examples = [gsm8k[i] for i in idxs]\n",
    "print(\"GSM8K subset size:\", len(gsm8k_examples))\n",
    "ppl_texts_mmlu = [ex[\"question\"] for ex in mmlu_examples]\n",
    "print(\"Perplexity texts mmlu:\", len(ppl_texts_mmlu))\n",
    "ppl_texts_gsm8k = [ex[\"question\"] for ex in gsm8k_examples]\n",
    "print(\"Perplexity texts gsm8k:\", len(ppl_texts_gsm8k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e546b965-eb0e-4fad-bc6a-32a83578f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation Utilities\n",
    "def compute_loglikelihood(model, tokenizer, prompt, continuation, max_length=512):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        full = prompt + continuation\n",
    "        enc = tokenizer(full, return_tensors=\"pt\", truncation=True, max_length=max_length ).to(device)\n",
    "\n",
    "        input_ids = enc[\"input_ids\"]\n",
    "        prompt_enc = tokenizer( prompt, return_tensors=\"pt\", truncation=True, max_length=max_length).to(device)\n",
    "        prompt_len = prompt_enc[\"input_ids\"].size(1)\n",
    "        labels = input_ids.clone()\n",
    "        labels[:, :prompt_len] = -100\n",
    "\n",
    "        out = model(input_ids=input_ids, labels=labels)\n",
    "        nll = out.loss.item() * (labels != -100).sum().item()\n",
    "        return -nll\n",
    "\n",
    "\n",
    "def evaluate_mmlu(model, tokenizer, mmlu_examples, max_length=512):\n",
    "    correct = 0\n",
    "    total = len(mmlu_examples)\n",
    "    for ex in mmlu_examples:\n",
    "        q = ex[\"question\"]\n",
    "        choices = ex[\"choices\"]\n",
    "        gold = ex[\"answer_idx\"]\n",
    "        prompt = (\n",
    "            \"Question: \" + q + \"\\n\" +\n",
    "            \"A. \" + choices[0] + \"\\n\" +\n",
    "            \"B. \" + choices[1] + \"\\n\" +\n",
    "            \"C. \" + choices[2] + \"\\n\" +\n",
    "            \"D. \" + choices[3] + \"\\n\" +\n",
    "            \"Answer:\"\n",
    "        )\n",
    "        labels = [\" A\", \" B\", \" C\", \" D\"]\n",
    "        scores = []\n",
    "        for cand in labels:\n",
    "            scores.append(compute_loglikelihood(model, tokenizer, prompt, cand, max_length))\n",
    "        pred = max(range(4), key=lambda i: scores[i])\n",
    "        if pred == gold:\n",
    "            correct += 1\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "number_pattern = re.compile(r\"(-?\\d+(\\.\\d+)?)\")\n",
    "\n",
    "def extract_last_number(text):\n",
    "    matches = number_pattern.findall(text)\n",
    "    if not matches:\n",
    "        return None\n",
    "    return matches[-1][0]\n",
    "\n",
    "\n",
    "def generate_answer(model, tokenizer, question, max_new_tokens=64):\n",
    "    prompt = \"Question: \" + question + \"\\nAnswer:\"\n",
    "    enc = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        out_ids = model.generate(\n",
    "            **enc,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            temperature=0.0,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    text = tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
    "    return text\n",
    "\n",
    "\n",
    "def evaluate_gsm8k(model, tokenizer, gsm8k_examples, max_new_tokens=64):\n",
    "    correct = 0\n",
    "    total = len(gsm8k_examples)\n",
    "    for ex in gsm8k_examples:\n",
    "        q = ex[\"question\"]\n",
    "        gt_answer_full = ex[\"answer\"]\n",
    "        gt_num = extract_last_number(gt_answer_full)\n",
    "\n",
    "        pred_full = generate_answer(model, tokenizer, q, max_new_tokens=max_new_tokens)\n",
    "        pred_num = extract_last_number(pred_full)\n",
    "\n",
    "        if gt_num is not None and pred_num is not None and gt_num == pred_num:\n",
    "            correct += 1\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def compute_perplexity(model, tokenizer, texts, max_length=256, batch_size=4):\n",
    "    model.eval()\n",
    "    total_nll = 0.0\n",
    "    total_tokens = 0\n",
    "    dl = DataLoader(texts, batch_size=batch_size, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in dl:\n",
    "            enc = tokenizer(\n",
    "                batch,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                padding=True,\n",
    "            ).to(device)\n",
    "\n",
    "            input_ids = enc[\"input_ids\"]\n",
    "            attention_mask = enc[\"attention_mask\"]\n",
    "            labels = input_ids.clone()\n",
    "            labels[attention_mask == 0] = -100\n",
    "\n",
    "            out = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = out.loss\n",
    "            n_tokens = attention_mask.sum().item()\n",
    "            total_nll += loss.item() * n_tokens\n",
    "            total_tokens += n_tokens\n",
    "\n",
    "    avg_nll = total_nll / total_tokens\n",
    "    ppl = math.exp(avg_nll)\n",
    "    return ppl\n",
    "\n",
    "\n",
    "def eval_fn(model, tokenizer):\n",
    "    print(\"  Evaluating MMLU...\")\n",
    "    acc_mmlu = evaluate_mmlu(model, tokenizer, mmlu_examples)\n",
    "    print(\"  Evaluating GSM8K...\")\n",
    "    acc_gsm8k = evaluate_gsm8k(model, tokenizer, gsm8k_examples)\n",
    "    print(\"  Evaluating perplexity...\")\n",
    "    #ppl_mmlu = compute_perplexity(model, tokenizer, ppl_texts_mmlu)\n",
    "    ppl_gsm8k = compute_perplexity(model, tokenizer, ppl_texts_gsm8k)\n",
    "    print(f\"  MMLU={acc_mmlu:.3f}, GSM8K={acc_gsm8k:.3f}, PPL GSM8K={ppl_gsm8k:.1f}\")\n",
    "    return acc_mmlu, acc_gsm8k, ppl_gsm8k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e69c290-1be4-48cb-9609-ebc54ccb1356",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Qwen3-0.6B Evaluation\n",
      "  Evaluating MMLU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluating GSM8K...\n",
      "  Evaluating perplexity...\n",
      "  MMLU=0.242, GSM8K=0.031, PPL GSM8K=17.2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      3\u001b[39m baseline_acc_mmlu, baseline_acc_gsm8k, baseline_ppl_gsm8k = eval_fn(base_model, tokenizer)\n\u001b[32m      4\u001b[39m baseline_results = {\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33mbaseline\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33macc_mmlu\u001b[39m\u001b[33m\"\u001b[39m: [baseline_acc_mmlu],\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33macc_gsm8k\u001b[39m\u001b[33m\"\u001b[39m: [baseline_acc_gsm8k],\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mppl_gsm8k\u001b[39m\u001b[33m\"\u001b[39m: [baseline_ppl_gsm8k],\n\u001b[32m      9\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m df_baseline = \u001b[43mpd\u001b[49m.DataFrame(baseline_results)\n\u001b[32m     11\u001b[39m df_baseline.to_csv(\u001b[33m\"\u001b[39m\u001b[33mbaseline_results.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_baseline)\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#Baseline Evaluation\n",
    "print(\"Baseline Qwen3-0.6B Evaluation\")\n",
    "baseline_acc_mmlu, baseline_acc_gsm8k, baseline_ppl_gsm8k = eval_fn(base_model, tokenizer)\n",
    "baseline_results = {\n",
    "    \"model_type\": [\"baseline\"],\n",
    "    \"acc_mmlu\": [baseline_acc_mmlu],\n",
    "    \"acc_gsm8k\": [baseline_acc_gsm8k],\n",
    "    \"ppl_gsm8k\": [baseline_ppl_gsm8k],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab9044d8-2900-4ce8-9493-4bf8c0f8d271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_type  acc_mmlu  acc_gsm8k  ppl_gsm8k\n",
      "0   baseline  0.241685   0.030534  17.205842\n"
     ]
    }
   ],
   "source": [
    "df_baseline = pd.DataFrame(baseline_results)\n",
    "df_baseline.to_csv(\"baseline_results.csv\", index=False)\n",
    "print(df_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19eb8f07-bdd9-4c70-8b0c-969b0405f2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MMLU and GSM8K subsets...\n",
      "MMLU subset size: 496\n",
      "GSM8K subset size: 131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nppl_texts_mmlu = [ex[\"question\"] for ex in mmlu_examples[:45]]\\nprint(\"Perplexity texts mmlu:\", len(ppl_texts_mmlu))\\nppl_texts_gsm8k = [ex[\"question\"] for ex in gsm8k_examples[:45]]\\nprint(\"Perplexity texts gsm8k:\", len(ppl_texts_gsm8k))\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build a LM training dataset for Router\n",
    "print(\"Loading MMLU and GSM8K subsets...\")\n",
    "\n",
    "#mmlu = load_dataset(\"cais/mmlu\", \"all\", split=\"train\")\n",
    "# We'll use the \"test\" split from a subset of subjects\n",
    "mmlu_subjects = [\n",
    "    \"abstract_algebra\",\n",
    "    \"high_school_physics\",\n",
    "    \"college_chemistry\",\n",
    "    \"high_school_computer_science\"\n",
    "]\n",
    "\n",
    "mmlu_examples_train = []\n",
    "#print(mmlu)\n",
    "for subj in mmlu_subjects:\n",
    "    ds = load_dataset(\"cais/mmlu\", subj, split=\"validation\")\n",
    "    #print(ds)\n",
    "\n",
    "    num_ex = min(100, len(ds[\"question\"]))\n",
    "    for idx in range(num_ex):\n",
    "        # Normalize choices/options\n",
    "        choices = ds[\"choices\"][idx] \n",
    "        answer_idx = ds[\"answer\"][idx]  \n",
    "\n",
    "        # Only keep four-choice questions\n",
    "        if len(choices) != 4:\n",
    "            continue\n",
    "    \n",
    "        mmlu_examples.append({\n",
    "            \"question\": ds[\"question\"][idx],\n",
    "            \"choices\": choices,\n",
    "            \"answer_idx\": int(answer_idx),\n",
    "        })\n",
    "\n",
    "print(\"MMLU subset size:\", len(mmlu_examples))\n",
    "gsm8k = load_dataset(\"openai/gsm8k\", \"main\", split=\"train\")\n",
    "\n",
    "gsm8k_examples_train = [gsm8k[i] for i in range(len(gsm8k))]\n",
    "print(\"GSM8K subset size:\", len(gsm8k_examples))\n",
    "\"\"\"\n",
    "ppl_texts_mmlu = [ex[\"question\"] for ex in mmlu_examples[:45]]\n",
    "print(\"Perplexity texts mmlu:\", len(ppl_texts_mmlu))\n",
    "ppl_texts_gsm8k = [ex[\"question\"] for ex in gsm8k_examples[:45]]\n",
    "print(\"Perplexity texts gsm8k:\", len(ppl_texts_gsm8k))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c06d185f-2871-4dc6-80ed-df812b7b2705",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "        input_ids = enc[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = enc[\"attention_mask\"].squeeze(0)\n",
    "        labels = input_ids.clone()\n",
    "        labels[attention_mask == 0] = -100\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "\n",
    "train_texts = []\n",
    "for ex in gsm8k_examples_train:\n",
    "    train_texts.append(ex[\"question\"])\n",
    "    if \"answer\" in ex and isinstance(ex[\"answer\"], str):\n",
    "        train_texts.append(ex[\"answer\"])\n",
    "for ex in mmlu_examples_train:\n",
    "    train_texts.append(ex[\"question\"])\n",
    "random.shuffle(train_texts)\n",
    "train_texts = train_texts[:1000]\n",
    "\n",
    "train_ds_lm = LMDataset(train_texts, tokenizer, max_length=128)\n",
    "train_loader_lm = DataLoader(train_ds_lm, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637352a6-9b67-49c5-ac2f-6c99472c47af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063b3592-84e8-44e6-a867-75327f5cd8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91b6f33f-a33c-4c57-bdeb-3f409a1bac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoHRouter(nn.Module):\n",
    "    \"\"\"\n",
    "    Mixture-of-Heads router:\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, num_heads, shared_ratio=0.25, top_k=4):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.shared = max(1, int(num_heads * shared_ratio))\n",
    "        self.routed = max(1, num_heads - self.shared)\n",
    "        self.top_k = min(top_k, self.routed)\n",
    "\n",
    "        self.W_s = nn.Linear(hidden_size, self.shared)\n",
    "        self.W_r = nn.Linear(hidden_size, self.routed)\n",
    "        self.W_h = nn.Linear(hidden_size, 2)\n",
    "\n",
    "        # small init to avoid huge logits\n",
    "        nn.init.xavier_uniform_(self.W_s.weight, gain=0.1)\n",
    "        nn.init.xavier_uniform_(self.W_r.weight, gain=0.1)\n",
    "        nn.init.xavier_uniform_(self.W_h.weight, gain=0.1)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        \"\"\"\"    \n",
    "        Input:\n",
    "           hidden_states\n",
    "        Output:\n",
    "           Output: per-head probabilities \n",
    "        \"\"\"\n",
    "        #use fp32 to avoid overflow and NaN\n",
    "        x = hidden_states.float() \n",
    "        scale = math.sqrt(self.hidden_size)\n",
    "\n",
    "        logits_h = self.W_h(x) / scale    \n",
    "        alpha = torch.softmax(logits_h, dim=-1)\n",
    "\n",
    "        s_scores = self.W_s(x) / scale\n",
    "        r_scores = self.W_r(x) / scale\n",
    "\n",
    "        s_soft = torch.softmax(s_scores, dim=-1)\n",
    "        r_soft = torch.softmax(r_scores, dim=-1)\n",
    "\n",
    "        # Top-k on routed heads\n",
    "        topk_idx = torch.topk(r_scores, k=self.top_k, dim=-1).indices\n",
    "        mask = torch.zeros_like(r_scores).scatter_(-1, topk_idx, 1.0)\n",
    "        r_masked = r_soft * mask\n",
    "\n",
    "        s_final = alpha[..., 0:1] * s_soft\n",
    "        r_final = alpha[..., 1:2] * r_masked\n",
    "\n",
    "        probs = torch.cat([s_final, r_final], dim=-1)\n",
    "        probs = torch.clamp(probs, 1e-6, 1.0 - 1e-6)\n",
    "        return probs\n",
    "\n",
    "\n",
    "class LlamaAttentionWithRouter(nn.Module):\n",
    "    \"\"\"\n",
    "    Wraps a LlamaAttention module with a MoH router.\n",
    "    \"\"\"\n",
    "    def __init__(self, attn_module, config, layer_idx, shared_ratio=0.25, top_k=4):\n",
    "        super().__init__()\n",
    "        assert isinstance(attn_module, LlamaAttention)\n",
    "        self.attn = attn_module\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.num_heads = config.num_attention_heads\n",
    "        self.head_dim = self.hidden_size // self.num_heads\n",
    "        self.layer_idx = layer_idx\n",
    "\n",
    "        self.router = MoHRouter(\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_heads=self.num_heads,\n",
    "            shared_ratio=shared_ratio,\n",
    "            top_k=top_k,\n",
    "        )\n",
    "\n",
    "        # Keep router in fp32 but on the same device as attention weights\n",
    "        ref_param = next(attn_module.parameters())\n",
    "        self.router = self.router.to(device=ref_param.device, dtype=torch.float32)\n",
    "\n",
    "        self.last_router_probs = None  \n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states,\n",
    "        attention_mask=None,\n",
    "        position_ids=None,\n",
    "        past_key_value=None,\n",
    "        output_attentions=False,\n",
    "        use_cache=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        # call to original LlamaAttention\n",
    "        out = self.attn(\n",
    "            hidden_states=hidden_states,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            past_key_value=past_key_value,\n",
    "            output_attentions=output_attentions,\n",
    "            use_cache=use_cache,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        if output_attentions:\n",
    "            attn_output, attn_weights, present_key_value = out\n",
    "        else:\n",
    "            attn_output, present_key_value = out\n",
    "            attn_weights = None\n",
    "\n",
    "        router_in = hidden_states.float()\n",
    "        router_probs = self.router(router_in)\n",
    "        self.last_router_probs = router_probs.to(hidden_states.dtype)\n",
    "\n",
    "        if output_attentions:\n",
    "            return attn_output, attn_weights, present_key_value\n",
    "        else:\n",
    "            return attn_output, present_key_value\n",
    "\n",
    "def convert_llama_to_router(model, shared_ratio=0.25, top_k=4):\n",
    "    \"\"\"\n",
    "    Replaces each LlamaAttention block with LlamaAttentionWithRouter.\n",
    "    \"\"\"\n",
    "    config = model.config\n",
    "    for i, layer in enumerate(model.model.layers):\n",
    "        attn = layer.self_attn\n",
    "        wrapped = LlamaAttentionWithRouter(\n",
    "            attn_module=attn,\n",
    "            config=config,\n",
    "            layer_idx=i,\n",
    "            shared_ratio=shared_ratio,\n",
    "            top_k=top_k,\n",
    "        )\n",
    "        layer.self_attn = wrapped\n",
    "    print(\"Converted LLaMA attention to LlamaAttentionWithRouter in all layers.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7211ad5c-ec4a-4355-b4ef-96c56a10d2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moh_load_balance_loss(model, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Compute load-balancing loss from router_probs in each layer.\n",
    "    For each layer:\n",
    "      - Take last_router_probs\n",
    "      - Average over batch+sequence \n",
    "      - Encourage it to be close to uniform (high entropy, low variance).\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    for layer in model.model.layers:\n",
    "        attn = layer.self_attn\n",
    "        if not isinstance(attn, LlamaAttentionWithRouter):\n",
    "            continue\n",
    "        probs = attn.last_router_probs  # [B,S,H] or None\n",
    "        if probs is None:\n",
    "            continue\n",
    "        # average over batch+sequence\n",
    "        p = probs.mean(dim=(0, 1))  \n",
    "        p = p / (p.sum() + eps)\n",
    "        # entropy term (maximize entropy == minimize -entropy)\n",
    "        entropy = -(p * (p + eps).log()).sum()\n",
    "        # variance term (want low variance)\n",
    "        var = p.var()\n",
    "        # Combine (neg entropy + var)\n",
    "        loss_layer = -entropy + var\n",
    "        losses.append(loss_layer)\n",
    "\n",
    "    if not losses:\n",
    "        return torch.tensor(0.0, device=next(model.parameters()).device)\n",
    "\n",
    "    return torch.stack(losses).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2463d6a9-4bed-41c8-a4eb-1c9266a41a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_router_head_importance(model, texts, max_length=128, batch_size=4, device=None):\n",
    "    \"\"\"\n",
    "    Use router_probs to compute per-head importance:\n",
    "      - For each batch, get last_router_probs per layer.\n",
    "      - Average over batch+sequence per head.\n",
    "    Returns: tensor [num_layers, num_heads]\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = next(model.parameters()).device\n",
    "\n",
    "    model.eval()\n",
    "    n_layers = model.config.num_hidden_layers\n",
    "    n_heads = model.config.num_attention_heads\n",
    "\n",
    "    head_importance = torch.zeros(n_layers, n_heads, device=device)\n",
    "    count = 0\n",
    "\n",
    "    dl = DataLoader(texts, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dl:\n",
    "            enc = tokenizer( list(batch), return_tensors=\"pt\", truncation=True, max_length=max_length, padding=True,).to(device)\n",
    "\n",
    "            outputs = model(**enc, labels=enc[\"input_ids\"])\n",
    "            # routers have updated last_router_probs\n",
    "            for i, layer in enumerate(model.model.layers):\n",
    "                attn = layer.self_attn\n",
    "                if not isinstance(attn, LlamaAttentionWithRouter):\n",
    "                    continue\n",
    "                probs = attn.last_router_probs  # [B,S,H]\n",
    "                if probs is None:\n",
    "                    continue\n",
    "                p = probs.mean(dim=(0, 1))  # [H]\n",
    "                head_importance[i] += p\n",
    "            count += 1\n",
    "\n",
    "    head_importance /= max(count, 1)\n",
    "    return head_importance\n",
    "\n",
    "def prune_heads_by_router_importance(model, head_importance, sparsity=0.2):\n",
    "    \"\"\"\n",
    "    Zero out the least important heads globally according to router-based importance.\n",
    "    \"\"\"\n",
    "    hi = head_importance.detach().cpu()\n",
    "    n_layers, n_heads = hi.shape\n",
    "    total_heads = n_layers * n_heads\n",
    "\n",
    "    num_to_prune = int(sparsity * total_heads)\n",
    "    if num_to_prune <= 0:\n",
    "        print(\"Nothing to prune.\")\n",
    "        return []\n",
    "\n",
    "    flat_scores = hi.view(-1)\n",
    "    prune_idx = torch.topk(flat_scores, k=num_to_prune, largest=False).indices\n",
    "\n",
    "    pairs = [(int(idx // n_heads), int(idx % n_heads)) for idx in prune_idx]\n",
    "\n",
    "    hidden_size = model.config.hidden_size\n",
    "    num_heads = model.config.num_attention_heads\n",
    "    head_dim = hidden_size // num_heads\n",
    "\n",
    "    print(f\"Pruning {num_to_prune}/{total_heads} heads \"\n",
    "          f\"({100.0 * sparsity:.1f}% sparsity)\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (layer_idx, head_idx) in pairs:\n",
    "            layer = model.model.layers[layer_idx]\n",
    "            attn = layer.self_attn.attn if isinstance(layer.self_attn, LlamaAttentionWithRouter) else layer.self_attn\n",
    "            q_proj = attn.q_proj\n",
    "            k_proj = attn.k_proj\n",
    "            v_proj = attn.v_proj\n",
    "            o_proj = attn.o_proj\n",
    "            start = head_idx * head_dim\n",
    "            end = (head_idx + 1) * head_dim\n",
    "            q_proj.weight[start:end, :] = 0\n",
    "            if q_proj.bias is not None:\n",
    "                q_proj.bias[start:end] = 0\n",
    "            k_proj.weight[start:end, :] = 0\n",
    "            if k_proj.bias is not None:\n",
    "                k_proj.bias[start:end] = 0\n",
    "            v_proj.weight[start:end, :] = 0\n",
    "            if v_proj.bias is not None:\n",
    "                v_proj.bias[start:end] = 0\n",
    "            o_proj.weight[:, start:end] = 0\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79b220e5-d892-4be8-934a-72e67c10681d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted LLaMA attention to LlamaAttentionWithRouter in all layers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-21): 22 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttentionWithRouter(\n",
       "          (attn): LlamaAttention(\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "            (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          )\n",
       "          (router): MoHRouter(\n",
       "            (W_s): Linear(in_features=2048, out_features=8, bias=True)\n",
       "            (W_r): Linear(in_features=2048, out_features=24, bias=True)\n",
       "            (W_h): Linear(in_features=2048, out_features=2, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_model = deepcopy(base_model)\n",
    "router_model = convert_llama_to_router(router_model, shared_ratio=0.25, top_k=4)\n",
    "router_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a2837e-5077-47e6-97b5-419d35063569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6243f22b-4357-4d08-88f6-13472514b66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable router params: 1,532,652\n"
     ]
    }
   ],
   "source": [
    "#freeze base model and unfreeze router params only\n",
    "for p in router_model.parameters():\n",
    "    p.requires_grad = False\n",
    "    \n",
    "router_params = []\n",
    "for layer in router_model.model.layers:\n",
    "    attn = layer.self_attn\n",
    "    if isinstance(attn, LlamaAttentionWithRouter):\n",
    "        for p in attn.router.parameters():\n",
    "            p.requires_grad = True\n",
    "            router_params.append(p)\n",
    "\n",
    "optimizer = torch.optim.AdamW(router_params, lr=5e-5)\n",
    "max_grad_norm = 1.0\n",
    "lambda_lb = 1.0  # weight for load-balance loss\n",
    "\n",
    "print(f\"Trainable router params: {sum(p.numel() for p in router_params):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd7d2e0-972b-4d4e-962c-b69a41aa44cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in p_values:\n",
    "    print(f\"Pruning target {p*100:.1f}%\")\n",
    "    torch.cuda.empty_cache()\n",
    "    m = deepcopy(base_model_cpu)\n",
    "    #'''\n",
    "    #model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16,device_map=\"auto\")\n",
    "    #m = model\n",
    "    #'''\n",
    "    pruner = MagnitudePruner(p)\n",
    "    actual = pruner.apply(m)\n",
    "    m = m.to(device)\n",
    "    acc_mmlu, acc_gsm8k, ppl_mmlu, ppl_gsm8k = eval_fn(m, tokenizer)\n",
    "    results_mag.append([actual, acc_mmlu, acc_gsm8k, ppl_mmlu, ppl_gsm8k])\n",
    "    #free gpu memory to avoid oom error\n",
    "    del m\n",
    "    #del pruner\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "df_mag = pd.DataFrame(results_mag, columns=[\"p_actual\", \"acc_mmlu\", \"acc_gsm8k\", \"ppl_mmlu\", \"ppl_gsm8k\"])\n",
    "df_mag.to_csv(\"magnitude_pruning_results.csv\", index=False)\n",
    "print(df_mag.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b543da1f-3cb7-4fae-a31b-9342874a9196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss=-0.7007\n",
      "Epoch 1, Loss=-0.7011\n",
      "Epoch 2, Loss=-0.7025\n",
      "Epoch 3, Loss=-0.7023\n",
      "Epoch 4, Loss=-0.7032\n",
      "Epoch 5, Loss=-0.7025\n",
      "Epoch 6, Loss=-0.7035\n",
      "Epoch 7, Loss=-0.7043\n",
      "Epoch 8, Loss=-0.7044\n",
      "Epoch 9, Loss=-0.7047\n",
      "Epoch 10, Loss=-0.7041\n",
      "Epoch 11, Loss=-0.7046\n",
      "Epoch 12, Loss=-0.7051\n",
      "Epoch 13, Loss=-0.7048\n",
      "Epoch 14, Loss=-0.7047\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "router_model.train()\n",
    "loss_list = []\n",
    "for epoch in range(epochs): \n",
    "    total_loss = 0\n",
    "    total_sample = 0\n",
    "    for step, batch in enumerate(train_loader_lm):\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = router_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        #outputs = router_model(**batch.to(device))\n",
    "        lm_loss = outputs.loss.float()\n",
    "        lb_loss = moh_load_balance_loss(router_model).float()\n",
    "\n",
    "        #train only routers (LM frozen) using LB loss\n",
    "        loss = lambda_lb * lb_loss\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(router_params, max_grad_norm)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_sample += batch[\"input_ids\"].shape[0]\n",
    "    total_loss /=total_sample\n",
    "    loss_list.append(total_loss)\n",
    "    print( f\"Epoch {epoch}, Loss={total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea07e536-8128-408b-a501-a9310ce183f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting router-based head importance...\n",
      "Router head importance shape: (22, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Collecting router-based head importance...\")\n",
    "router_head_importance = collect_router_head_importance(\n",
    "    router_model,\n",
    "    ppl_texts_gsm8k,\n",
    "    max_length=128,\n",
    "    batch_size=4,\n",
    "    device=device,\n",
    ")\n",
    "router_head_importance_np = router_head_importance.detach().cpu().numpy()\n",
    "print(\"Router head importance shape:\", router_head_importance_np.shape)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(router_head_importance_np, aspect=\"auto\")\n",
    "plt.colorbar(label=\"Router-based head importance\")\n",
    "plt.xlabel(\"Head index\")\n",
    "plt.ylabel(\"Layer index\")\n",
    "plt.title(\"MoH Router-based Head Importance (TinyLlama)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d3b3dce-e214-4008-b475-49130398a230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 140/704 heads (20.0% sparsity)\n",
      "Total pruned heads: 140\n",
      "Re-evaluating perplexity after router-guided head pruning...\n",
      "Baseline PPL: 17.21\n"
     ]
    }
   ],
   "source": [
    "# Evaluate router-guided head pruning on a fresh copy of base model\n",
    "sparsity = 0.2\n",
    "pruned_model = deepcopy(base_model).to(device)\n",
    "pruned_heads = prune_heads_by_router_importance(\n",
    "    pruned_model,\n",
    "    router_head_importance,\n",
    "    sparsity=sparsity,\n",
    ")\n",
    "\n",
    "print(\"Total pruned heads:\", len(pruned_heads))\n",
    "print(\"Re-evaluating perplexity after router-guided head pruning...\")\n",
    "print(f\"Baseline PPL: {baseline_ppl_gsm8k:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f42fb90-f1f6-4429-8d92-3633f37a3810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned model evaluation Evaluation\n",
      "  Evaluating MMLU...\n",
      "  Evaluating GSM8K...\n",
      "  Evaluating perplexity...\n",
      "  MMLU=0.228, GSM8K=0.031, PPL GSM8K=29.5\n"
     ]
    }
   ],
   "source": [
    "#Baseline Evaluation\n",
    "print(\"Pruned model evaluation Evaluation\")\n",
    "pruned20_acc_mmlu, pruned20_acc_gsm8k, pruned20_ppl_gsm8k = eval_fn(pruned_model, tokenizer)\n",
    "pruned20_results = {\n",
    "    \"model_type\": [\"baseline\"],\n",
    "    \"acc_mmlu\": [pruned20_acc_mmlu],\n",
    "    \"acc_gsm8k\": [pruned20_acc_gsm8k],\n",
    "    \"ppl_gsm8k\": [pruned20_ppl_gsm8k],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f0f913-8675-4f9a-8000-32c3ce80695c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec4e49e3-154b-4bcc-876d-68b1054bc493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_type  acc_mmlu  acc_gsm8k  ppl_gsm8k\n",
      "0   baseline  0.241685   0.030534  17.205842\n"
     ]
    }
   ],
   "source": [
    "print(df_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f20b551e-53db-46c5-889a-6b6d7c051e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 281/704 heads (40.0% sparsity)\n",
      "Total pruned heads: 281\n",
      "Re-evaluating perplexity after router-guided head pruning...\n",
      "Baseline PPL: 29.51\n",
      "Pruned model evaluation Evaluation\n",
      "  Evaluating MMLU...\n",
      "  Evaluating GSM8K...\n",
      "  Evaluating perplexity...\n",
      "  MMLU=0.208, GSM8K=0.031, PPL GSM8K=75.2\n"
     ]
    }
   ],
   "source": [
    "# Evaluate router-guided head pruning on a fresh copy of base model\n",
    "sparsity = 0.4\n",
    "pruned_model = deepcopy(base_model).to(device)\n",
    "pruned_heads = prune_heads_by_router_importance(\n",
    "    pruned_model,\n",
    "    router_head_importance,\n",
    "    sparsity=sparsity,\n",
    ")\n",
    "\n",
    "print(\"Total pruned heads:\", len(pruned_heads))\n",
    "print(\"Re-evaluating perplexity after router-guided head pruning...\")\n",
    "print(f\"Baseline PPL: {baseline_ppl_gsm8k:.2f}\")\n",
    "#Baseline Evaluation\n",
    "print(\"Pruned model evaluation Evaluation\")\n",
    "pruned40_acc_mmlu, pruned40_acc_gsm8k, pruned40_ppl_gsm8k = eval_fn(pruned_model, tokenizer)\n",
    "pruned40_results = {\n",
    "    \"model_type\": [\"baseline\"],\n",
    "    \"acc_mmlu\": [pruned40_acc_mmlu],\n",
    "    \"acc_gsm8k\": [pruned40_acc_gsm8k],\n",
    "    \"ppl_gsm8k\": [pruned40_ppl_gsm8k],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f11eaae-ee3d-450b-814d-c698e0d16883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 211/704 heads (30.0% sparsity)\n",
      "Total pruned heads: 211\n",
      "Re-evaluating perplexity after router-guided head pruning...\n",
      "Baseline PPL: 75.19\n",
      "Pruned model evaluation Evaluation\n",
      "  Evaluating MMLU...\n",
      "  Evaluating GSM8K...\n",
      "  Evaluating perplexity...\n",
      "  MMLU=0.220, GSM8K=0.031, PPL GSM8K=39.1\n"
     ]
    }
   ],
   "source": [
    "#evaluate router-guided head pruning on a fresh copy of base model\n",
    "sparsity = 0.3\n",
    "pruned_model = deepcopy(base_model).to(device)\n",
    "pruned_heads = prune_heads_by_router_importance(\n",
    "    pruned_model,\n",
    "    router_head_importance,\n",
    "    sparsity=sparsity,\n",
    ")\n",
    "\n",
    "print(\"Total pruned heads:\", len(pruned_heads))\n",
    "print(\"Re-evaluating perplexity after router-guided head pruning...\")\n",
    "print(f\"Baseline PPL: {baseline_ppl_gsm8k:.2f}\")\n",
    "#Baseline Evaluation\n",
    "print(\"Pruned model evaluation Evaluation\")\n",
    "pruned30_acc_mmlu, pruned30_acc_gsm8k, pruned30_ppl_gsm8k = eval_fn(pruned_model, tokenizer)\n",
    "pruned30_results = {\n",
    "    \"model_type\": [\"baseline\"],\n",
    "    \"acc_mmlu\": [pruned30_acc_mmlu],\n",
    "    \"acc_gsm8k\": [pruned30_acc_gsm8k],\n",
    "    \"ppl_gsm8k\": [pruned30_ppl_gsm8k],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777c972f-c58a-42ec-bd30-3bee2338786b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
